Extracting robust and discriminative features is critical in many medical
image processing applications. Many conventional methods rely on
hand-engineered features, which often do not perform well enough for tasks
like segmentation, recognition and registration; learning-based methods
usually require point correspondence as ground-truth; and most unsupervised
learning methods do not explicitly model the invariance for features and thus
could not guarantee actual performance.  To address these problems, we propose
a feature extractor by explicitly requiring robustness and discriminative
power in the loss function of a deep convolutional neural network that is
trained in an unsupervised manner. We also propose a new feature evaluation
protocol that could directly estimate the performance of a learned feature,
without either relying on other image processing tasks whose results are used
to infer feature performance or requiring any manually labeled point
correspondence. Experiment results suggest that our learned features are
better than stacked convolutional ISA and may further improve related medical
image processing algorithms.

% vim: filetype=text foldmethod=marker foldmarker=f{{{,f}}} spell spelllang=en
