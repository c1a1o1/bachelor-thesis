% $File: intro.tex
% $Date: Wed Jun 10 21:20:49 2015 +0800
% $Author: jiakai <jia.kai66@gmail.com>

\chapter{绪论\label{chap:intro}}

\section{研究背景}
对医学影像的获取、分析和处理在现代医疗工作中占有重要地位。
常用的基于放射的医学成像技术包括计算机体层成像(Computed Tomography, CT)、
磁共振成像(Magnetic Resonance Imaging, MRI)等。在医学影像技术的辅助下，
人们可以非侵入式的直接观察到患者体内的情况，
对疾病的诊治和人体科学的研究都有重大意义。

对医学影像的分析和处理也是计算机科学相关领域长久以来研究的热点。
但由于其本身的难度以及对结果精确度的极高要求，这方面的自动化方法远不成熟，
只能作为人工辅助，临床上也一般由训练有素的医生来完成对影像的分析工作。
一般而言，医学影像的如下特点使得对其的自动化处理较为困难：
\begin{inparaenum}[\itshape 1\upshape)]
    \item 分辨率不高，如CT的图像矩阵往往只有$512\times 512$\cite{medimging2}；
    \item 来源单一而封闭，需要大型扫描设备，而且涉及患者隐私；
    \item 由于人体构造、扫描时体位等不同而呈现很大差异性，
        病变部位则更是千差万别；
    \item 维度高，一般为3D体数据，或者带时间信息的4D图像。
\end{inparaenum}

许多医学影像处理算法及一般的图像处理算法并不直接处理原始图像数据，
而是先从原始图像上提取特征，再在特征空间上进行后续处理。
一般而言，特征提取包括检测关键点(或关键区域)和计算特征描述子(或称特征表示，
feature descriptor/representation)两步，
在本文中我们着重于描述子的计算，并只考虑图像上逐点密集计算的特征描述子，
因此用``特征提取''一词代表计算特征描述子的过程。

图像处理中的特征提取指用低维的特征向量来描述高维的原始图像数据的过程。
原始图像数据一般包含大量冗余信息，例如相邻像素间差异的分布就往往集中于零点附近。
特征提取本质上就是对数据进行降维和去冗余，一个好的特征要能很好地描述原始图像，
应该同时具有鲁棒性和区分性。鲁棒性是指当原始图像经过平移、旋转、拉伸、亮度调整
等一些简单变换后，特征应该尽量不变；区分性是指对不同的图像，特征也应该尽量不同。

近年来随着互联网的高速发展带来的海量数据，
以及GPU技术的成熟和普及带来的高密度高速计算能力，
深度学习逐渐成为一种实用的高性能通用模型，并在图像分类\cite{he2015delving}、
人脸识别\cite{schroff2015facenet}等领域的特定数据集上超过了人类水平。
但目前将深度学习用于在医学影像上进行特征提取的工作并不多。因此，
本文将尝试使用基于非监督学习的深度学习算法，自动从CT扫描数据中提取特征，
并基于本文提出的评测方法测试各种特征的性能。

\section{研究现状}
学术界在特征提取、医学影像处理、深度学习等领域都有非常丰富的研究成果，
在本节中我们不会详细回顾所有的相关工作，
而仅仅对与本文密切相关的部分进行简要介绍。

在特征提取方面，有许多经典方法，大致可分为人工设计和非监督学习两大类。
人工设计的特征描述子，如LBP\cite{ojala1994performance}、
HOG\cite{dalal2005histograms}、SIFT\cite{lowe1999object}、
SURF\cite{bay2006surf}等，往往通过数学推导给特征引入所期望的不变性，
不会主动适配目标应用，不过在许多经典问题上都能取得不错的效果。
这些特征大部分是为2D图像设计的，也有少部分被扩展到了3D，
如3D-SIFT\cite{scovanner20073}。
非监督学习的特征描述子，可以主动适配到目标应用领域上，
有主成分分析、独立成分分析、独立子空间分析等统计方法，
也有受限玻尔兹曼机、自动编码器等可以学习深层特征的模型。
这方面的详细总结可以参考Bengio等人的工作\cite{bengio2013representation}。

需要指出的是，常见的非监督特征学习的方法往往基于概率模型。
其基本假设是使用少量参数对输入的概率分布$p(\vec{x})$进行建模，
如果该模型能较好地重建输入，则认为它提取了原始输入信息背后更本质的特征。
然而本文采取的方法并没有引入概率表述，而更类似判别学习的方法，
在监督信号中直接引入对鲁棒性和区分性的要求。
在这方面，与本文比较类似的是Dosovitskiy等人的工作
\cite{dosovitskiy2014discriminative}，
其作者通过构建辅助分类来训练卷积神经网络并用于物体识别，
而在本文中我们除了多分类外还尝试了度量学习作为损失函数，
对训练数据量、特征距离度量等因素对性能的影响也进行了更详尽的探讨。

在医学影像处理方面，本文并没有大量涉及该领域相关的内容。
与本文比较相关的是Wu等人的工作\cite{wu2013unsupervised}，
其作者使用层叠卷积ISA进行非监督特征学习，并用于大脑磁共振影像的配准。
但本文主要关注特征提取本身，并不使用具体的医学影像处理相关的任务来评价特征性能，
而是提出了新的特征评价标准。有了好的特征后，
一些传统的配准方法(如HAMMER\cite{shen2002hammer}、
多通道微分同胚demon\cite{peyrat2010registration})、
分割方法(如\cite{ling2008hierarchical})等都可能从中获益。

深度学习是近年来热门的研究领域。相关技术可用于监督学习、非监督学习等学习范式，
并用于供判别模型和生成模型。
关于深度学习更详细的讨论可以参考Bengio的工作\cite{bengio2009learning}。
本文采用深度卷积神经网络，其基本模型已在十多年前提出\cite{lecun1998gradient}，
在近年来通过使用更深、更大的网络，更多的训练数据，
以及网络设计和训练过程中的一些技巧，这类模型在许多任务上都取得了不错的性能。


\section{主要贡献与创新点}
本文主要在以下几个方面作出了一定贡献：

\begin{enumerate}
    \item 实现了层叠卷积ISA方法\cite{wu2013unsupervised}，
        并采用了多GPU的数据并行，极大提高了训练速度，
        相关代码已开源托管在\url{https://github.com/jia-kai/bachelor-thesis}；
    \item 在腹腔CT扫描影像上使用深度卷积神经网络进行非监督特征学习，
        通过实验论证其性能在我们的评测标准下优于层叠卷积ISA方法，
        并且进行了细致的实验来比较训练过程中的各种参数选择对最终性能的影响；
    \item 提出了新的特征评测标准，不需要依赖于特征在
        分割或配准等更复杂的任务上的表现来间接评价其性能，
        仅需要对某特定器官的分割标注作为额外输入，简明直接地评价特征性能。
\end{enumerate}

\section{论文组织}
本文的组织安排如下：

\chapref{intro}对研究背景、研究现状和本文的主要创新点进行了综述。

\chapref{ISA}介绍了层叠卷积ISA模型的基本原理及训练时的并行实现，
同时指出其缺陷以引出后续方法。

\chapref{CNN}介绍了本文所使用的深度卷积网络模型，
详细说明了其设计动机和损失函数的选择，并介绍了对3D影像数据进行增广的具体方法。

\chapref{expr}阐述了本文提出的特征评测方法，并给出了具体实验数据和结果的细节，
对实验结果进行了讨论。

\chapref{discuss}对本文的研究工作进行总结，并展望了未来的相关研究。

% vim: filetype=tex foldmethod=marker foldmarker=f{{{,f}}}
